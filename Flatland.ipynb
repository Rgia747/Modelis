{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qOww_3bepUsk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pirmiausia turime apdoroti duomenis į pytorch datasetą"
      ],
      "metadata": {
        "id": "d2tt6_QjtbJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapesDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, images_array, labels_array, transform=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.x = torch.from_numpy(images_array).float()\n",
        "        self.y = torch.from_numpy(labels_array).long()\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.x = self.transform(self.x)\n",
        "        \n",
        "    # Kad žinotumėme dataseto ilgį\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    \n",
        "    # Kad galėtumėme išsiimti bet kurį elementą iš dataseto\n",
        "    def __getitem__(self, idx):\n",
        "        img_tensor = self.x[idx]\n",
        "        \n",
        "        # Jei reikia, naudojame transformacijas\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_tensor)\n",
        "        \n",
        "        return img_tensor, self.y[idx]"
      ],
      "metadata": {
        "id": "b-3fKXk5pgkN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sukuriame pagrindinę neuroninio modelio klasę"
      ],
      "metadata": {
        "id": "GLrS-G3itted"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapesNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes):\n",
        "        super(ShapesNet, self).__init__()\n",
        "        \n",
        "        # Sukuriami konvoliuciniai sluoksniai\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, \n",
        "                                out_channels=4, \n",
        "                                kernel_size=5, \n",
        "                                stride=2, \n",
        "                                padding=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=4, \n",
        "                                out_channels=8, \n",
        "                                kernel_size=3, \n",
        "                                stride=2, \n",
        "                                padding=1)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=8, \n",
        "                                out_channels=16, \n",
        "                                kernel_size=3, \n",
        "                                stride=2, \n",
        "                                padding=1)\n",
        "        \n",
        "        # Sukuriami normalizacijos sluoksniai batch'ams\n",
        "        self.bn_1 = nn.BatchNorm2d(num_features=4)\n",
        "        self.bn_2 = nn.BatchNorm2d(num_features=8)\n",
        "        self.bn_3 = nn.BatchNorm2d(num_features=16)\n",
        "        self.bn_4 = nn.BatchNorm1d(num_features=100)\n",
        "        \n",
        "        # Sukuriami linijiniai sluoksniai\n",
        "        self.fc_1 = nn.Linear(in_features=16 * 6 * 6,\n",
        "                                out_features=100)\n",
        "        self.fc_out = nn.Linear(in_features=100,\n",
        "                                out_features=n_classes)\n",
        "        \n",
        "    # Metodas, skirtas paskaičiuoti modelio outputą\n",
        "    def forward(self, x):\n",
        "        x = self.bn_1(F.leaky_relu(self.conv_1(x)))\n",
        "        x = self.bn_2(F.leaky_relu(self.conv_2(x)))\n",
        "        x = self.bn_3(F.leaky_relu(self.conv_3(x)))\n",
        "        x = self.bn_4(F.leaky_relu(self.fc_1(torch.reshape(x, (-1, 16 * 6 * 6)))))\n",
        "        \n",
        "        return self.fc_out(x)"
      ],
      "metadata": {
        "id": "XqUVPfoEpmW5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Užsikrauname failą ir apdorojame duomenis"
      ],
      "metadata": {
        "id": "4lBZ7oVC0-e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Užsikrauname failą\n",
        "data = np.load('flatland_train.npz')\n",
        "x = data['X']\n",
        "y = data['y']\n",
        "\n",
        "# Padarome kad klasės būtų nuo 0 iki 4\n",
        "y = y - 2\n",
        "y[y < 0] = 0\n",
        "\n",
        "# Išskiriam duomenis iš train test imtis\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "x_train = np.expand_dims(x_train, axis=1)\n",
        "x_test = np.expand_dims(x_test, axis=1)\n",
        "\n",
        "# Sukuriam transformacijos objektą\n",
        "transform = transforms.Compose([transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "# Sukuriam datasetai iš numpy arrays\n",
        "shapes_trainset = ShapesDataSet(x_train, \n",
        "                                y_train, \n",
        "                                transform=transform)\n",
        "shapes_testset = ShapesDataSet(x_test, \n",
        "                               y_test, \n",
        "                               transform=transform)\n",
        "\n",
        "# Sukuriam dataloaderius, kurie bus naudojami modelio mokyme\n",
        "shapes_dataloader_train = DataLoader(shapes_trainset,\n",
        "                                     batch_size=100,\n",
        "                                     shuffle=True)\n",
        "shapes_dataloader_test = DataLoader(shapes_testset,\n",
        "                                     batch_size=1,\n",
        "                                     shuffle=True)"
      ],
      "metadata": {
        "id": "Zu8U_hNHpvIL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Galime sukurti norimo image atvaizdavimo funkciją ir jį atvaizduoti:"
      ],
      "metadata": {
        "id": "WJRqHa_MuCls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_image(image_array):\n",
        "    plt.imshow(image_array, cmap='gray')"
      ],
      "metadata": {
        "id": "3Qee31uHpr4g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Atvaizduojamas bet koks image iš dataseto\n",
        "idx = 5000\n",
        "image_array = x_train[idx].reshape(50, 50)\n",
        "plot_image(image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "QIiHrszEp2bT",
        "outputId": "07a8e911-ce67-4cc0-bde8-5d7c49de0f1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Galime paskaičiuoti, kiek unikalių reikšmių turės modelis"
      ],
      "metadata": {
        "id": "HnzjbUrC19jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(np.unique(y))\n",
        "np.unique(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0dpfABFp5B2",
        "outputId": "e97a58c1-4b46-4704-b567-84996dbafd4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apibrėžiame modelio treniravimui reikalingas reikšmes"
      ],
      "metadata": {
        "id": "Oe7MoXpj7g4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kadangi naudojamos konvoliucijos, tai pasižiūrima, ar galima bus naudoti GPU, o ne CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "g1iMqix6p7QT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializuojama klasė\n",
        "shapes_net = ShapesNet(n_classes).to(device)\n"
      ],
      "metadata": {
        "id": "qg1whRYPp9f7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nurodoma, kiek bus epochų\n",
        "n_epochs = 10\n",
        "# Inicializuojamas optimizuotojas\n",
        "optim = torch.optim.AdamW(shapes_net.parameters(),\n",
        "                          lr=0.001)\n",
        "# Inicializuojama loss funkcija\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ownnIz1HqAbl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dabar galime pereiti prie modelio treniravimo"
      ],
      "metadata": {
        "id": "0QhDwWec2kJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    # Sukuriami kintamieji, kurie savyje laikys treniravimo rezultatus\n",
        "    total_loss_train = 0\n",
        "    total_loss_valid = 0\n",
        "    train_correct_preds = 0\n",
        "    valid_correct_preds = 0\n",
        "    \n",
        "    # Nurodoma, kad modelis bus treniravimo rėžime\n",
        "    shapes_net.train()\n",
        "    \n",
        "    # 1-os epochos modelio mokymo loop'as\n",
        "    for images, labels in shapes_dataloader_train:\n",
        "        # Images and labels užkraunami į nurodytą device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Nunulinami gradientai, kadangi pytorch jų nenunulina (jei šios funkcijos nenaudotume, tai gradientai būtų be sustojimo kaupiami)\n",
        "        optim.zero_grad()\n",
        "        # Gaunami modelio spėjimai\n",
        "        preds = shapes_net(images)\n",
        "        \n",
        "        train_correct_preds += torch.argmax(preds, dim=1).eq(labels).sum().item()\n",
        "        \n",
        "        # Paskaičiuojamas modelio loss'as\n",
        "        loss = criterion(preds, labels)\n",
        "        # Paskaičiuojami modelio gradientai pagal loss'ą\n",
        "        loss.backward()\n",
        "        # Paupdatinami modelio parametrai pagal gradientus\n",
        "        optim.step()\n",
        "        \n",
        "    shapes_net.eval()\n",
        "    \n",
        "    #  Modelio rezultatų atvaizdavimui vizualiai \n",
        "    with torch.no_grad():\n",
        "        for images, labels in shapes_dataloader_test:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            preds = shapes_net(images)\n",
        "            valid_correct_preds += torch.argmax(preds, dim=1).eq(labels).sum().item()\n",
        "\n",
        "            loss = criterion(preds, labels)\n",
        "            \n",
        "    train_binary_accuracy_pct = round(train_correct_preds / len(shapes_dataloader_train.dataset) * 100, 2)\n",
        "    valid_binary_accuracy_pct = round(valid_correct_preds / len(shapes_dataloader_test.dataset) * 100, 2)\n",
        "        \n",
        "    print(f'Epoch: {epoch + 1}, training set accuracy: {train_binary_accuracy_pct}%, Validation set accuracy: {valid_binary_accuracy_pct}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1SnESvuqDar",
        "outputId": "a951ffc5-c49a-4ef8-9f57-cf1a4315370b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, training set accuracy: 50.7%, Validation set accuracy: 60.5%\n",
            "Epoch: 2, training set accuracy: 68.97%, Validation set accuracy: 70.2%\n",
            "Epoch: 3, training set accuracy: 79.17%, Validation set accuracy: 75.2%\n",
            "Epoch: 4, training set accuracy: 84.88%, Validation set accuracy: 81.1%\n",
            "Epoch: 5, training set accuracy: 89.54%, Validation set accuracy: 84.9%\n",
            "Epoch: 6, training set accuracy: 93.51%, Validation set accuracy: 88.55%\n",
            "Epoch: 7, training set accuracy: 95.25%, Validation set accuracy: 89.85%\n",
            "Epoch: 8, training set accuracy: 96.95%, Validation set accuracy: 90.75%\n",
            "Epoch: 9, training set accuracy: 97.55%, Validation set accuracy: 91.55%\n",
            "Epoch: 10, training set accuracy: 98.31%, Validation set accuracy: 92.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Išsaugome modelį:"
      ],
      "metadata": {
        "id": "DFyDhK8B7CIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = shapes_net\n",
        "torch.save(model, 'model.h5')"
      ],
      "metadata": {
        "id": "Ly2I0Sah0fEr"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}